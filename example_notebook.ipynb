{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UOrtos\n",
    "\n",
    "`UOrtos` is an open source software to obtain a set of outlier-free co-registered and georeferenced satellite images with high alignment quality.\n",
    "\n",
    "### Description\n",
    "The algorithm for co-registration and georeferentation of satellite images assumes that images can be realigned through an isometric transformation. The image alignment is achieved by minimising the distances between common image features. Clustering techniques are used to obtain a high quality set of aligned images without outliers. As a result of the process, the metadata information related to the geotransformation of the satellite images (GeoTIFF) is corrected and co-registered PNG images are derived. The development of this software is aimed for obtaining images to accurately determine shoreline displacements. In general, it can be used for the precise detection of features at different times. Details about the algorithm and methodology are described in\n",
    "> *Simarro, G.; Calvete, D.; Ribas, F.; Castillo Y.; Puig-Polo, C. UOrtos: A Python Tool for Subpixel co-registration of Landsat and Sentinel 2 Imagery. Remote Sens. 2025, xx, xxxx. https://doi.org/10.3390/rs12345678*\n",
    "\n",
    "The co-registration process consists of the following steps:\n",
    "\n",
    "1. [Image downloading](#image-download)\n",
    "2. [Feature pairing](#feature-pairing)\n",
    "3. [Image clustering](#clustering)\n",
    "4. [Outputs](#output)\n",
    "\n",
    "### Requirements and project structure\n",
    "To run the software it is necessary to have Python (3.12) and install the following dependencies:\n",
    "- cv2 (4.1.0)\n",
    "- numpy (2.1.0)\n",
    "- scipy (1.14.1)\n",
    "- osgeo (3.9.1)\n",
    "- ee (1.418)\n",
    "\n",
    "In parenthesis we indicate the version with which the software has been tested. It is possible that it works with older versions.\n",
    "\n",
    "The structure of the project is the following:\n",
    "* `example.py`\n",
    "* `example_notebook.py`\n",
    "* **`uortos`**\n",
    "  * `uortos.py`\n",
    "  * `ulises_uortos.py`\n",
    "* **`example`**\n",
    "  * **`data`**\n",
    "    * `parameters.json`\n",
    "    * `satellites.json`\n",
    "    * `<res01>_<domain01>_reference.tif`\n",
    "  * **`output`**\n",
    "    * **`<parameter_set_01>`**\n",
    "      * **`<res01>_<domain01>`**\n",
    "        * `<time-stamp>.log`\n",
    "        * `<ref_image>.ref`\n",
    "        * **`geopng`**\n",
    "          * `<image01>.png`\n",
    "          * . . .\n",
    "        * **`tif`**\n",
    "          * **`<image01>`**\n",
    "            * `<image01>_<band01>.tif`\n",
    "            * . . .\n",
    "          * . . .\n",
    "      * . . .\n",
    "    * . . .\n",
    "  * **`scratch`**\n",
    "    * . . .\n",
    "\n",
    "The local modules of `UOrtos` are located in the **`uortos`** folder. Folder **`scratch`** contains auxiliary files for the coregistration process. Once completed, the files can be deleted. If the process is rerun, the auxiliary files are automatically deleted if they are no longer needed and the `clean` parameter is set to `True` in the `parameters.json` file. To make use of the GDAL (https://gdal.org) utilities, here the software developed by OSGEO (https://www.osgeo.org) has been used. It can be downloaded from https://github.com/OSGeo/gdal. In case of using another implementation of GDAL, `ulises_uortos.py` must be modified accordingly. \n",
    "\n",
    "To run a demo in folder **`example`** experienced users can run the `example.py` file in a terminal. Alternatively we provide the file `example_notebook.ipynb` to be used in a Jupyter Notebook. In that case, import modules and set the main path of the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, 'uortos')\n",
    "import uortos as uortos\n",
    "pathFldMain = 'example'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set also the data files in the folder **`data`** containing the parameters for the coregistration process (`parameters.json`) and the information related to the downloading of satellite images (`satellites.json`). This second file should not be modified unless you have expertise in the storage of satellite images. These files are read below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathJson = os.path.join(pathFldMain, 'data', 'parameters.json')\n",
    "with open(pathJson, 'r') as f:\n",
    "    par = json.load(f)\n",
    "#\n",
    "pathJson = os.path.join(pathFldMain, 'data', 'satellites.json')\n",
    "with open(pathJson, 'r') as f:\n",
    "    par.update(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of these files will be described in the different steps of the process. If any of the values are modified, the process must be restarted from the beginning.\n",
    "\n",
    "## Image downloading\n",
    "The images are downloaded through the Google Earth Engine (GEE). The first time images are downloaded, it will be necessary to authenticate in the GEE. You need to link the image downloading to a Google Cloud Project and provide the project name in `eeProject` in the file `parameters.json`.\n",
    "\n",
    "| Object-name | Description | Example value | \n",
    "|:--|:--:|:--:|\n",
    "| `eeProject` | Google Cloud Project  | `\"ee-yourname\"` |\n",
    "\n",
    "Sustitute `\"ee-yourname\"` for the actual name of the project. Authenticate and initializate GEE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project=par['eeProject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information needed to download the required images must be specified in the `satellites.json` and `parameters.json` files. The satellites, spectral bands and resolutions to be used must be set in the file `satellites.json`. This file contains the following parameters:\n",
    "\n",
    "| Object-name | Description | Example value | \n",
    "|:--|:--:|:--:|\n",
    "| `satCode2ICode` | Image collection for each satellite code | `\"S2\": \"COPERNICUS/S2_HARMONIZED\"` |\n",
    "| `satCode2RGBBandsCodes` | Indices specifying the RGB-bands for each satellite code | `\"S2\": [\"B4\", \"B3\", \"B2\"]` |\n",
    "| `satCode2DownloadBandsCodes` |  Downloaded/output band for each satellite code | `\"S2\": \"all\"` |\n",
    "| `satCode2ResCodes` | List of resolutions codes for each satellite code | `\"S2\": [\"R30\", \"R10\"]` |\n",
    "| `resCode2Res` | Values (m) for each resolution code | `\"R30\": 30.0` |\n",
    "\n",
    "Note that the algorithm processes simultaneously collections of images from different satellites. The different resolutions are processed and clustered separately.\n",
    "\n",
    "The spatial domain and the temporal period of the images to be co-registered, as well as the amount of clouds in the images and the resolutions to work with, are set in the file `parameters.json`. This file contains the following parameters:\n",
    "\n",
    "| Object-name | Description | Example value | \n",
    "|:--|:--:|:--:|\n",
    "| `time0` | Initial time period  | `\"2024-01-01\"` |\n",
    "| `time1` | Final time period | `\"2025-01-01\"` |\n",
    "| `domainCode2Limits` | Coordinates for each domain code | `\"CFA\": [ 1.94, 2.03, 41.26, 41.30]` |\n",
    "| `domainCode2Projection` | Filter in the metadata projection for each domain code | `\"CFA\": \"UTM zone 31N\"` |\n",
    "| `cloudThres` | Maximum cloud threshold on the images | `25` |\n",
    "| `resCodes` | Resolution codes to use | `[\"R10\", \"R30\"]` |\n",
    "\n",
    "The image domains are rectangles oriented in the direction of the cardinal directions and defined by the longitude and latitude of each of the edges in the following order `[long-E, long-W, lat-S, lat-N]`. For   each domain code, images whose projection metadata does not contain the characters set in `domainCode2Projection` are discarded. In case `domainCode2Projection` for a given domain codes is `“”`, no filtering is performed. Download the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uortos.DownloadImages(pathFldMain, par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature pairing\n",
    "In a first phase, pairs of common features between the images are obtained using ORB or SIFT method. These pairs are purged by performing a RANSAC (RANdom SAmple Consensus) which evaluates the quality of the projected pairs from image to image using transformation of rotation and translation. The points fit the transformations when the distance between projected pairs is less than `errorsC1`. To ensure the quality of the points used for the transformation, it is also required that the distance of the farthest points verify a minimum ratio, `fractions`, of the horizontal and vertical dimension of the image. In addition, the points must be well distributed across the images. This is set by the parameters `nsPairs` and `nsBoxes`. In some cases it is not necessary to correct the rotation between images, adjust the `rotations` parameter accordingly. The parameters for adjusting this process can be found in the file `parameters.json`:\n",
    "\n",
    "| Object-name | Description | Example value | \n",
    "|:--|:--:|:--:|\n",
    "| `methodFM` | Feature Matching method | `\"SIFT\"` |\n",
    "| `limFM` | Maximum number of images to match each image | `15` |\n",
    "| `nsFM` | List of maximum number of features | `[1000]` |\n",
    "| `errorsC1` | Errors in the RANSAC transformations (in pixels) | `[1.0]` |\n",
    "| `fractions` | Minimum distance between the furthest points (fraction of the image size) | `[0.6]` |\n",
    "| `nsPairs` | Minumin number of boxes with points | `[5]` |\n",
    "| `nsBoxes` | Minumun number of boxes in the grid images | `[50]` |\n",
    "| `rotations` | Option to select whether transformations include rotations | `[\"free\", \"null\"]` |\n",
    "\n",
    "Set `limFM` to `0` for avoiding limits. Execute the codes to obtain the first selection of matching pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uortos.FMPairs(pathFldMain, par, par['limFM'] > 0)\n",
    "uortos.PurgePairs(pathFldMain, par, 'fm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the position of the matched pairs is adjusted by cross-correlation of the images around the points. This process increases the quality of the matches. The error tolerance is set with the parameter `errorsC2` found in the file `parameters.json`:\n",
    "\n",
    "| Object-name | Description | Example value | \n",
    "|:--|:--:|:--:|\n",
    "| `errorsC2` | Errors in the RANSAC transformations (in pixels)  | `[0.2]` |\n",
    "\n",
    "Run the code to obtain a final selection of pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uortos.CorPairs(pathFldMain, par)\n",
    "uortos.PurgePairs(pathFldMain, par, 'cor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image clustering\n",
    "This step takes advantage of the fact that certain images are linked through transformations. Using these connections, the largest cluster of related images is created. Within a cluster, any image can be transformed into another image using these relationships. To ensure high quality connections and filter out outliers, a minimum number of connections per image is required, set by the parameter `conDegrees`. In addition, the quality of the cluster can be further improved by increassing the number of iterations `nSets`. Both parameters are defined in the `parameters.json` file:\n",
    "\n",
    "| Object-name | Description | Example value | \n",
    "|:--|:--:|:--:|\n",
    "| `conDegrees` | Degree of connections | `[2]` |\n",
    "| `nSets` | Iterations in the refining process  | `500` |\n",
    "\n",
    "Execute the code to get the cluster of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uortos.Affines(pathFldMain, par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "As a result of the process, the metadata information related to the geotransformation of the satellite images (GeoTIFF) is corrected and co-registered PNG images are derived. \n",
    "      \n",
    "Execute the code to get the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uortos.Output(pathFldMain, par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output images are located in the folder `output`. For each set of parameters, a folder labelled with the parameter values collects the coregistered images. The label of this folder is coded as follows:\n",
    "\n",
    "`<parameter_set_01>`=`\"nsFM\"_\"errorsC1\"_\"fractions\"_\"nsPairs\"_\"nsBoxes\"_\"rotations\"_\"errorsC2\"_\"conDegrees\"`\n",
    "\n",
    "Where the numeric values have been written without comma. Each folder contains subfolders named `<res01>_<domain01>`, where `<res01>` is the image resolution code and `<domain01>` is the spatial domain code. Inside these subfolders, you will find the `geopng` and `tif` directories. Additionally, within the `<res01>_<domain01>` folder the georeference information, extracted from the metadata of the most _centered_ image of the output images, is stored in the file `<ref_image>.ref`. The structure of this file is the following:\n",
    "* One line for each corner pixel\n",
    ">`pixel-column`, `pixel-row`, `x-coordinate`, `y-coordinate`\n",
    "\n",
    "If the `<res01>_<domain01>_reference.tif>` image, which can be optionally provided in the `data` folder, is part of the output images, it will be used for `<ref_image>.ref`. Otherwise, the most _centered_ image will be selected. The `scratch` folder contains the original images downloaded from GEE, organized following the structure of `output`. Once the georeferencing process has been completed, it is recommended to delete the `scratch` folder.\n",
    "\n",
    "## Contact us\n",
    "\n",
    "Are you experiencing problems? Do you want to give us a comment? Do you need to get in touch with us? Please contact us!\n",
    "\n",
    "To do so, we ask you to use the [Issues section](https://github.com/Ulises-ICM-UPC/UOrtos/issues) instead of emailing us.\n",
    "\n",
    "## Contributions\n",
    "\n",
    "Contributions to this project are welcome. To do a clean pull request, please follow these [guidelines](https://github.com/MarcDiethelm/contributing/blob/master/README.md).\n",
    "\n",
    "## License\n",
    "\n",
    "UOrtos is released under a [GPLv3 license](https://github.com/Ulises-ICM-UPC/UOrtos/blob/main/LICENSE). If you use UOrtos in an academic work, please cite:\n",
    "\n",
    "    @Article{rs12345678,\n",
    "      AUTHOR = {Simarro, Gonzalo and Calvete, Daniel and Ribas, Francesca and Castillo, Yerai and {Puig-Polo}, Carol},\n",
    "      TITLE = {UOrtos: A Python Tool for Subpixel co-registration of Landsat and Sentinel 2 Imagery},\n",
    "      JOURNAL = {Remote Sensing},\n",
    "      VOLUME = {xx},\n",
    "      YEAR = {2025},\n",
    "      NUMBER = {xx},\n",
    "      ARTICLE-NUMBER = {xxxx},\n",
    "      URL = {https://www.mdpi.com/2072-4292/xx/xx/xxxx},\n",
    "      ISSN = {2072-4292},\n",
    "      DOI = {10.3390/rs12345678}\n",
    "      }\n",
    "\n",
    "    @Online{ulisesortos, \n",
    "      author = {Simarro, Gonzalo and Calvete, Daniel},\n",
    "      title = {UOrtos},\n",
    "      year = 2025,\n",
    "      url = {https://github.com/Ulises-ICM-UPC/UOrtos}\n",
    "      }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
